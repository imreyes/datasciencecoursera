quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
library(ISLR); library(ggplot2); library(caret)
library(ISLR); library(ggplot2); library(caret); data(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass, data = training)
head(predict(dummies, newdata = training))
class(dummies)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv
library(spline)
library(splines)
bsBasis <- bs(training$age, df = 3)
bsBasis
lm1 <- lm(wage ~ bsBasis, data = training)
plot(training$age, training$wage, pch = 19, cex = 0.5)
points(training$age, predict(lm1, newdata = training), col = 'red', pch = 19, cex = 0.5)
summary(lm1)
?bs
predict(bsBasis, age = testing$age)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
M <- abs(cor(training[, -58]))
diag(M) <- 0
which(M > 0.8, arr.ind = TRUE)
plot(spam[, 34], spam[, 32])
smallSpam <- spam[, c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1], prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type == 'spam') * 1 + 1)
prComp <-prcomp(log10(spam[, -58] + 1))
plot(prComp$x[,1], prComp$x[,2], col = typeColor, xlab = 'PC1', ypab = 'PC2')
plot(prComp$x[,1], prComp$x[,2], col = typeColor, xlab = 'PC1', ylab = 'PC2')
warnings()
plot(prComp$x[,1], prComp$x[,2], col = typeColor, xlab = 'PC1', ylab = 'PC2')
preProc <- preProcess(log10(spam[, -58] + 1), method = 'pca', pcaComp = 2)
spamPC <- predict(preProc, log10(spam[, -58] + 1))
plot(spamPC[,1], spamPC[,2], col = typeColor)
trainPC <- predict(preProc, log10(training[, -58] + 1))
modelFit <- train(training$type ~ ., method = 'glm', data = trainPC)
testPC <- predict(preProc, log10(testing[, -58] + 1))
confusionMatrix(testing$type, predict(modelFit, testPC))
confusionMatrix(testing$type, predict(modelFit, testPC))
testPC <- predict(preProc, log10(testing[, -58] + 1))
confusionMatrix(testing$type, predict(modelFit, testPC))
confusionMatrix(testing$type, predict(modelFit, testPC))
preProc <- preProcess(log10(spam[, -58] + 1), method = 'pca', pcaComp = 2)
spamPC <- predict(preProc, log10(spam[, -58] + 1))
plot(spamPC[,1], spamPC[,2], col = typeColor)
trainPC <- predict(preProc, log10(training[, -58] + 1))
modelFit <- train(training$type ~ ., method = 'glm', data = trainPC)
preProc <- preProcess(log10(spam[, -58] + 1), method = 'pca', pcaComp = 2)
spamPC <- predict(preProc, log10(spam[, -58] + 1))
plot(spamPC[,1], spamPC[,2], col = typeColor)
trainPC <- predict(preProc, log10(training[, -58] + 1))
modelFit <- train(training$type ~ ., method = 'glm', data = trainPC)
modelFit <- train(training$type ~ ., method = 'glm', data = trainPC)
dim(trainPC)
dim(training)
modelFit <- train(training$type ~ ., method = 'glm', preProcess = 'pca', data = training)
confusionMatrix(testing$type, predict(modelFit, testPC))
?preProcess
library(caret); data(faithful)
set.seed(333)
inTrain <- createDataPartition(y = faithful$waiting,
p = 0.5, list = FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
library(caret); data(faithful)
set.seed(333)
inTrain <- createDataPartition(y = faithful$waiting,
p = 0.5, list = FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch = 19, col = 'blue')
lm1 <- lm(eruptions ~ waiting, data = trainFaith)
summary(lm1)
lines(trainFaith$waiting, lm1$fitted.values, lwd = 3)
coef(lm1)[1] + coef(lm1)[2] * 80
predict(lm1, newdata = data.frame(waiting = 80))
par(mfrow = c(1, 2))
par(mfrow = c(1, 2))
plot(trainFaith$waiting, trainFaith$eruptions, pch = 19, col = 'blue')
lines(trainFaith$waiting, predict(lm1), lwd = 3)
plot(testFaith$waiting, testFaith$eruptions, pch = 19, col = 'blue')
lines(testFaith$waiting, predict(lm1, newdata = testFaith), lwd = 3)
sqrt(sum((lm1$fitted - trainFaith$eruptions) ^ 2))
sqrt(sum((predict(lm1, newdata = testFaith) - testFaith$eruptions) ^ 2))
resid(lm1)
sd(resid(lm1))
mean(resid(lm1))
deviance(lm1)
pred1 <- prediction(lm1, newdata = testFaith, interval = 'preiction')
pred1 <- prediction(lm1, newdata = testFaith, interval = 'prediction')
pred1 <- predict(lm1, newdata = testFaith, interval = 'prediction')
ord <- order(testFaith$waiting)
plot(testFaith$waiting, testFaith$eruptions, pch = 19, col = 'blue')
matlines(testFaith$waiting[ord], pred1[ord], type = 'l', col = c(1,2,2), lty = c(1,1,1), lwd = 3)
par(mfrow = c(1,1))
pred1 <- predict(lm1, newdata = testFaith, interval = 'prediction')
ord <- order(testFaith$waiting)
plot(testFaith$waiting, testFaith$eruptions, pch = 19, col = 'blue')
matlines(testFaith$waiting[ord], pred1[ord], type = 'l', col = c(1,2,2), lty = c(1,1,1), lwd = 3)
matlines(testFaith$waiting[ord], pred1[ord], type = 'l', , col = c(1,2,2), lty = c(1,1,1), lwd = 3)
matlines(testFaith$waiting[ord], pred1[ord], type = 'l', , col = c(1,2,2), lty = c(1,1,1), lwd = 3)
pred1 <- predict(lm1, newdata = testFaith, interval = 'prediction')
ord <- order(testFaith$waiting)
plot(testFaith$waiting, testFaith$eruptions, pch = 19, col = 'blue')
matlines(testFaith$waiting[ord], pred1[ord], type = 'l', , col = c(1,2,2), lty = c(1,1,1), lwd = 3)
matlines(testFaith$waiting[ord], pred1[ord,], type = 'l', , col = c(1,2,2), lty = c(1,1,1), lwd = 3)
class(pred1)
dim(pred1)
dim(testFaith)
head(pred1)
modFit <- train(eruptions ~ waiting, dat = trainFaith, method = 'lm')
summary(modFit$finalModel)
library(ISLR); library(ggplot2); library(caret); data(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
Wage <- subset(Wage, select = c(logwage))
summary(Wage)
Wage <- subset(Wage, select = -c(logwage))
summary(Wage)
library(ISLR); library(ggplot2); library(caret); data(Wage)
Wage <- subset(Wage, select = -c(logwage))
summary(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
featurePlot(x = training[, c('age', 'education', 'jobclass')],
y = training$wage,
plot = 'pairs')
featurePlot(x = training[, c('age', 'education', 'jobclass')],
y = training$wage,
plot = 'pairs')
qplot(age, wage, col = jobclass, data = training)
qplot(age, wage, col = education, data = training)
modFit <- train(wage ~ age + jobclass + education,
method = 'lm', data = training)
fitMod <- modFit$finalModel
print(modFit)
modFit$finalModel
plot(fitMod, 1, pch = 19, cex = 0.5)
qplot(fitMod$fitted, fitMod$residuals, col = race, data = training)
plot(fitMod$residuals, pch = 19)
pred <- predict(modFit, testing)
qplot(wage, pred, col = year, data = testing)
modFitAll <- train(wage ~ ., data = training, method = 'lm')
pred <- predict(modFitAll, testing)
qplt(wage, pred, data = testing)
qplot(wage, pred, data = testing)
library(AppliedPredictiveModeling)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
data(concrete)
library(caret)
set.seed(1000)
inTrain <- createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training <- mixtures[inTrain, ]
testing <- mixtures[-inTrain, ]
dim(mixtures)
head(mixtures)
?cut2
qplot(CompressiveStrength, col = cut2(Cement, g = 5), data = training)
plot(CompressiveStrength, col = cut2(Cement, g = 5), data = training)
qplot(CompressiveStrength, col = cut2(Cement, g = 5), data = training)
plot(training$CompressiveStrength, col = cut2(training$Cement, g = 5))
plot(training$CompressiveStrength, col = cut2(training[,1], g = 5))
dim(training)[2]
sapply(1:(dim(training)[2] - 1), function(i) plot(training$CompressiveStrength, col = cut2(training[,i], g = 5))
sapply(1:(dim(training)[2] - 1), function(i) plot(training$CompressiveStrength, col = cut2(training[,i], g = 5)))
sapply(1:(dim(training)[2] - 1), function(i) plot(training$CompressiveStrength, col = cut2(training[,i], g = 5), main = names(training[, i])))
names(training[,2])
names(training)[2]
sapply(1:(dim(training)[2] - 1), function(i) plot(training$CompressiveStrength, col = cut2(training[,i], g = 5), main = names(training)[i]))
sapply(1:(dim(training)[2] - 1), function(i) plot(training$CompressiveStrength, col = cut2(training[,i], g = 3), main = names(training)[i]))
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
summary(log(training$Superplasticizer))
summary(training$Superplasticizer)
set.seed(3433)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
dim(training)
head(training[,1:7])
varIdx <- grep('IL', names(training))
length(varIdx)
varIdx
names(training)[varIdx]
varIdx <- grep('^IL', names(training))
names(training)[varIdx]
preProc <- preProcess(training[, varIdx], method = 'pca', pcaComp = 2)
var(training[, varIdx])
prc <- svd(training[,varIdx])
prc$d
evar <-sqrt(prc$d^2/sum(prc$d^2))
plot(evar)
evar
evar <- prc$d^2/sum(prc$d^2)
plot(evar)
evar
preProc <- preProcess(training[, varIdx], method = 'pca', pcaComp = 2)
trainPC <- predict(preProc, training[, varIdx])
class(trainPC)
dim(trainPC)
?preProcess
preProc <- preProcess(training[, varIdx], method = 'pca', thresh = 0.9)
trainPC <- predict(preProc, training[, varIdx])
dim(trainPC)
preProc <- preProcess(training[, varIdx], method = 'pca', thresh = 0.8)
dim(preProc)
modelFit <- train(training$diagnosis ~ training[,varIdx], method = 'glm')
trainingSub <- training[, c(varIdx, 'diagnosis')]
trainingSub <- cbind(training$diagnosis, training[,varIdx])
head(trainingSub)
modelFit <- train(diagnosis ~ ., method = 'glm', data = trainingSub)
modelFit <- train(diagnosis ~ ., method = 'glm', data = trainingSub)
trainingSub <- cbind(training$diagnosis, training[,varIdx])
modelFit <- train(diagnosis ~ ., method = 'glm', data = trainingSub)
length(trainingSub$diagnosis)
head(trainingSub)
head(training[1:10])
trainingSub <- training[, c(1,varIdx)]
modelFit <- train(diagnosis ~ ., method = 'glm', data = trainingSub)
confusionMatrix(testing$diagnosis, predict(modelFit, testing[,varIdx]))
confusionMatrix(testing$diagnosis, predict(preProc, testing[,varIdx]))
testPC <- predict(preProc, testing[, varIdx])
confusionMatrix(testing$diagnosis, predict(preProc, testPC))
modelFit2 <- train(diagnosis ~ ., method = 'glm', data = trainingSub)
modelFit2 <- train(diagnosis ~ ., method = 'glm', data = trainPC)
head(trainPC)
trainPC <- cbind(training[,1], predict(preProc, training[, varIdx]))
head(trainPC)
trainPC <- cbind(diagnosis = training[,1], predict(preProc, training[, varIdx]))
head(trainPC)
modelFit2 <- train(diagnosis ~ ., method = 'glm', data = trainPC)
testPC <- predict(preProc, testing[, varIdx])
confusionMatrix(testing$diagnosis, predict(preProc, testPC))
testPC <- cbind(diagnosis = testing[,1], predict(preProc, testing[, varIdx]))
confusionMatrix(testPC$diagnosis, predict(preProc, testPC))
confusionMatrix(testPC$diagnosis, predict(modelFit2, testPC))
preProc <- preProcess(training[, varIdx], method = 'pca', thresh = 0.8)
trainPC <- cbind(diagnosis = training[,1], predict(preProc, training[, varIdx]))
modelFit2 <- train(diagnosis ~ ., method = 'glm', data = trainPC)
testPC <- cbind(diagnosis = testing[,1], predict(preProc, testing[, varIdx]))
confusionMatrix(testPC$diagnosis, predict(modelFit2, testPC))
install.packages('rattle')
library(rattle)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(ggplot2); data(iris); library(caret)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species,
p = 0.7, list = FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
qplot(training$Petal.Width, training$Sepal.Width,
col = training$Species)
modFit <- train(Species ~ ., method = 'rpart', data = training)
modFit$finalModel
plot(modFit$finalModel)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rpart)
install.packages('rpart')
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages('rpart.plot')
install.packages("rpart.plot")
library(ggplot2); data(iris); library(caret)
table(iris$Species)
names(iris)
inTrain <- createDataPartition(y = iris$Species,
p = 0.7, list = FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
qplot(training$Petal.Width, training$Sepal.Width,
col = training$Species)
modFit <- train(Species ~ ., method = 'rpart', data = training)
modFit$finalModel
plot(modFit$finalModel)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predit(modFit, newdata = testing)
predict(modFit, newdata = testing)
install.packages('ElemStatLearn')
library(ElemStatLearn); data(ozone, package = 'ElemStatLearn')
ozone <- ozone[order(ozone$ozone), ]
head(ozone)
ll <- matrix(NA, nrow = 10, ncol = 155)
ll[i, ] <- predict(loess0, newdata = data.frame(ozone = 1:155))
for(i in 1:10){
ss <- sample(1:dim(ozone)[1], replace = TURE)
ozone0 <- ozone[ss, ]
ozone0 <- ozone0[order(ozone0$ozone), ]
loess0 <- loess(temperature ~ ozone, data = ozone0, span = 0.2)
ll[i, ] <- predict(loess0, newdata = data.frame(ozone = 1:155))
}
for(i in 1:10){
ss <- sample(1:dim(ozone)[1], replace = TRUE)
ozone0 <- ozone[ss, ]
ozone0 <- ozone0[order(ozone0$ozone), ]
loess0 <- loess(temperature ~ ozone, data = ozone0, span = 0.2)
ll[i, ] <- predict(loess0, newdata = data.frame(ozone = 1:155))
}
plot(ozone$ozone, ozone$temperature, pch = 19, cex = 0.5)
for(i in 1:10) {lines(1:155, ll[i, ], col = 'grey', lwd = 2)}
lines(1:155, apply(ll, 2, mean), col = 'red', lwd = 2)
predictors <- data.frame(ozone = ozone$ozone)
temperature <- ozone$temperature
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
install.packages('party')
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
install.packages('multcomp')
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
install.packages('strucchange')
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
plot(ozone$ozone, temperature, col = 'lightgrey', pch = 19)
points(ozone$ozone, predict(treebag$fits[[1]]$fit, predictors), pch = 19, col = 'red')
points(ozone$ozone, predict(treebag, predictors), pch = 19, col = 'blue')
data(iris); library(ggplot2)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
modFit <- train(Species ~ ., data = training, method = 'rf', prox = TRUE)
modFit <- train(Species ~ ., data = training, method = 'rf', prox = TRUE)
modFit
getTree(modFit$finalModel, k = 2)
irisP <- classCenter(training[, c(3, 4)], training$Species, modFit$finalModel$prox)
irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col = Species, data = training)
p + geom_point(aes(x = Petal.Width, y = Petal.Length, col = Species), size = 5, shape = 4, data = irisP)
irisP <- as.data.frame(irisP)
irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col = Species, data = training)
p + geom_point(aes(x = Petal.Width, y = Petal.Length, col = Species), size = 5, shape = 4, data = irisP)
irisP <- classCenter(training[, c(3, 4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP)
irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col = Species, data = training)
p + geom_point(aes(x = Petal.Width, y = Petal.Length, col = Species), size = 5, shape = 4, data = irisP)
pred <- predit(modFit, testing)
testing$predRight <- pred == testing$Species
table(pred, testing$Species)
pred <- predict(modFit, testing)
testing$predRight <- pred == testing$Species
table(pred, testing$Species)
qplot(Petal.Width, Petal.Length, col = predRight, data = testing)
setwd('c:/Users/GY/datasciencecoursera/PracticalMachineLearning/Week4_ProgrammingAssignment/')
setwd("G:/R")
trainUrl <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
testUrl <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
if(!file.exists('pml-training.csv')) download.file(trainUrl, destfile = 'pml-training.csv')
if(!file.exists('pml-testing.csv')) download.file(testUrl, destfile = 'pml-testing.csv')
rawdat <- read.csv('pml-training.csv', na.strings = c('',NA))
dat <- rawdat[, !is.na(rawdat[1, ])]
dat <- dat[, -c(1, 3:7)]
library(caret)
corMat <- cor(dat[, -c(1,54)])
heatmap(corMat)                                 # There are some high correlations.
rmCol <- findCorrelation(corMat, cutoff = 0.8)  # Lowering cutoff reduce volume.
finaldat <- dat[, -rmCol]
rmCol2 <- findCorrelation(cor(finaldat[, -41]), cutoff = 0.8)
finaldat <- finaldat[, -rmCol2]
set.seed(123)
inVal <- createDataPartition(finaldat$classe, p = 0.1, list = F)
validation <- finaldat[inVal,]
training <- finaldat[-inVal,]
set.seed(314)
idx <- createFolds(training$classe, k = 5)
library(caret); library(MASS)
AccLDA <- sapply(seq_along(idx), function(i) {
modFit <- lda(classe ~ ., data = training[-idx[[i]],])
pred <- predict(modFit, training[idx[[i]],])
# In-sample error.
mean(pred$class == training[idx[[i]],]$classe)
})
AccLP <- sapply(seq_along(idx), function(i) {
modFit <- train(classe ~ ., data = training[-idx[[i]],],
method = 'lda', preProcess = 'pca')
pred <- predict(modFit, training[idx[[i]],])
# In-sample error.
mean(pred == training[idx[[i]],]$classe)
})
library(rpart)
modFit <- rpart(classe ~ ., data = training[-idx[[1]],], method = 'class')
pred <- predict(modFit, training[idx[[1]],])
pred <- sapply(1:dim(pred)[1], function(i) names(which.max(pred[i,])))
Acc <- mean(pred == training[idx[[1]],]$classe)
Pool <- sapply(seq_along(idx), function(i) {
modFit <- rpart(classe ~ ., data = training[-idx[[i]],], method = 'class')
names(modFit[order(modFit$variable.importance, decreasing = T)]$variable.importance)[1:30]
})
Bestrank <- sapply(1:30, function(i) {
votes <- table(Pool[i,])
winner <- votes[order(votes, decreasing = TRUE)]
names(winner[1])
})
Best10 <- unique(Bestrank[1:10])
training10 <- training[, c(Best10,'classe')]
AccR <- sapply(seq_along(idx), function(i) {
modFit <- rpart(classe ~ ., data = training10[-idx[[i]],])
pred <- predict(modFit, training10[idx[[i]],])
pred <- sapply(1:dim(pred)[1], function(i) names(which.max(pred[i,])))
# In-sample error.
mean(pred == training10[idx[[i]],]$classe)
})
library(randomForest)
set.seed(213)
modFit <- randomForest(classe ~ ., data = training[-idx[[1]],],
ntree = 100, importance = TRUE)
varImpPlot(modFit, cex = 0.6)
set.seed(253)
Pool <- sapply(seq_along(idx), function(i) {
modFit <- randomForest(classe ~ ., data = training[-idx[[i]],],
ntree = 100, importance = TRUE)
Imp <- modFit$importance[,6]
names(Imp[order(Imp, decreasing = TRUE)])[1:30]
})
Bestrank <- sapply(1:30, function(i) {
votes <- table(Pool[i,])
winner <- votes[order(votes, decreasing = TRUE)]
names(winner[1])
})
Best10 <- unique(Bestrank[1:10])
training10 <- training[, c(Best10, 'classe')]
Best10 <- unique(Bestrank)[1:10]
training10 <- training[, c(Best10, 'classe')]
set.seed(132)
AccRF <- sapply(seq_along(idx), function(i) {
modFit <- randomForest(classe ~ ., data = training10[-idx[[1]],])
pred <- predict(modFit, training10[idx[[1]],])
mean(pred == training10[idx[[1]],]$classe)
})
mean(AccRF)
finaldat10 <- finaldat[, unique(Bestrank)[1:10]]
modFit <- randomForest(classe ~ ., data = finaldat10)
finaldat10 <- finaldat[, c(unique(Bestrank)[1:10], 'classe')]
modFit <- randomForest(classe ~ ., data = finaldat10)
datTest <- read.csv('pml-testing.csv', na.strings = c('', NA))
datTest <- datTest[, c(unique(Bestrank)[1:10])]
pred <- predict(modFit, newdata = datTest)
pred
install.packages('shiny')
library(shiny)
setwd('c:/Users/GY/datasciencecoursera')
dir.create('DevelopingDataProduct')
setwd('DevelopingDataProduct/')
dir.create('MyFirstShiny')
setwd('MyFirstShiny/')
library(shiny)
shinyUI(fluidPage(
titlePanel('Data Science FTW!'),
sidebarLayout(
sidebarPanel(
h3('Sidebar Text')
),
mainPanel(
h3('Main Panel Text')
)
)
))
runApp('~/MyFirstShiny')
runApp('~/MyFirstShiny')
runApp('C:/Users/GY/datasciencecoursera/DevelopingDataProduct/MyFirstShiny')
runApp()
runApp()
?builder
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("c:/Users/GY/datasciencecoursera/DevelopingDataProduct")
setwd("c:/Users/GY/datasciencecoursera/DevelopingDataProduct/PlotGraph")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
